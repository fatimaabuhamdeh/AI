{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhcgc9rTObo+L55liqldBu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatimaabuhamdeh/AI/blob/main/Data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps in Data Preprocessing:\n",
        "\n",
        "1.Importing the libraries\n",
        "\n",
        "2.Importing the dataset\n",
        "\n",
        "3.Drop Duplicate data\n",
        "\n",
        "4.Taking care of missing data\n",
        "\n",
        "5.Encoding categorical data\n",
        "\n",
        "6.Normalizing the data\n",
        "\n",
        "7.Handling Imbalance data\n",
        "\n",
        "8.Splitting the data into test and train"
      ],
      "metadata": {
        "id": "DmMSDhjzJ9b4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RpzL97btJ05q"
      },
      "outputs": [],
      "source": [
        "#1.Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Importing the dataset\n",
        "df = pd.read_csv('/content/DataPreprocessingGraded_dataset.csv')\n",
        "print (df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCbuKf10NT3Z",
        "outputId": "bff16683-a8d7-499e-f638-b2d9a1be126d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       V1    V2       V3    V4        V5 Target\n",
            "0     2.0  50.0  12500.0  98.0  NEGATIVE    YES\n",
            "1     0.0  13.0   3250.0  28.0  NEGATIVE    YES\n",
            "2       ?     ?   4000.0  35.0  NEGATIVE    YES\n",
            "3       ?  20.0   5000.0  45.0  NEGATIVE    YES\n",
            "4     1.0  24.0   6000.0  77.0  NEGATIVE     NO\n",
            "..    ...   ...      ...   ...       ...    ...\n",
            "743  23.0   2.0    500.0  38.0  NEGATIVE     NO\n",
            "744  21.0   2.0    500.0  52.0  NEGATIVE     NO\n",
            "745  23.0   3.0    750.0  62.0  NEGATIVE     NO\n",
            "746  39.0   1.0    250.0  39.0  NEGATIVE     NO\n",
            "747  72.0   1.0    250.0  72.0  NEGATIVE     NO\n",
            "\n",
            "[748 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Drop Duplicate data\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6LR1BNFNhKf",
        "outputId": "ae59f4aa-1434-4866-b388-b70fd9f46c68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX3uZGYaNmNh",
        "outputId": "716a185a-17e9-436f-f5db-c30492a0d9fb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.Taking care of missing data\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otl7pVfcNuVi",
        "outputId": "5b261e1e-ff7a-4418-8f0c-cc7d125db13d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "Target    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5.Encoding categorical data\n",
        "one_hot_encoded_data = pd.get_dummies(df)\n",
        "print(one_hot_encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWk8HyyFNxgL",
        "outputId": "cf41057c-9398-4b3d-b329-3d80face4ee9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          V3    V4  V1_0.0  V1_1.0  V1_10.0  V1_11.0  V1_12.0  V1_13.0  \\\n",
            "0    12500.0  98.0       0       0        0        0        0        0   \n",
            "1     3250.0  28.0       1       0        0        0        0        0   \n",
            "2     4000.0  35.0       0       0        0        0        0        0   \n",
            "3     5000.0  45.0       0       0        0        0        0        0   \n",
            "4     6000.0  77.0       0       1        0        0        0        0   \n",
            "..       ...   ...     ...     ...      ...      ...      ...      ...   \n",
            "743    500.0  38.0       0       0        0        0        0        0   \n",
            "744    500.0  52.0       0       0        0        0        0        0   \n",
            "745    750.0  62.0       0       0        0        0        0        0   \n",
            "746    250.0  39.0       0       0        0        0        0        0   \n",
            "747    250.0  72.0       0       0        0        0        0        0   \n",
            "\n",
            "     V1_14.0  V1_15.0  ...  V2_5.0  V2_50.0  V2_6.0  V2_7.0  V2_8.0  V2_9.0  \\\n",
            "0          0        0  ...       0        1       0       0       0       0   \n",
            "1          0        0  ...       0        0       0       0       0       0   \n",
            "2          0        0  ...       0        0       0       0       0       0   \n",
            "3          0        0  ...       0        0       0       0       0       0   \n",
            "4          0        0  ...       0        0       0       0       0       0   \n",
            "..       ...      ...  ...     ...      ...     ...     ...     ...     ...   \n",
            "743        0        0  ...       0        0       0       0       0       0   \n",
            "744        0        0  ...       0        0       0       0       0       0   \n",
            "745        0        0  ...       0        0       0       0       0       0   \n",
            "746        0        0  ...       0        0       0       0       0       0   \n",
            "747        0        0  ...       0        0       0       0       0       0   \n",
            "\n",
            "     V2_?  V5_NEGATIVE  Target_NO  Target_YES  \n",
            "0       0            1          0           1  \n",
            "1       0            1          0           1  \n",
            "2       1            1          0           1  \n",
            "3       0            1          0           1  \n",
            "4       0            1          1           0  \n",
            "..    ...          ...        ...         ...  \n",
            "743     0            1          1           0  \n",
            "744     0            1          1           0  \n",
            "745     0            1          1           0  \n",
            "746     0            1          1           0  \n",
            "747     0            1          1           0  \n",
            "\n",
            "[533 rows x 70 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6.Normalizing the data\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "scaler = Normalizer()\n",
        "scaled_data = scaler.fit_transform(one_hot_encoded_data)\n",
        "scaled_df = pd.DataFrame(scaled_data,\n",
        "                         columns=one_hot_encoded_data.columns)\n",
        "print(scaled_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_b1sgTPOKsu",
        "outputId": "138face5-ded7-4b91-ea52-530bcc1c795e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         V3        V4    V1_0.0    V1_1.0  V1_10.0  V1_11.0  V1_12.0  V1_13.0  \\\n",
            "0  0.999969  0.007840  0.000000  0.000000      0.0      0.0      0.0      0.0   \n",
            "1  0.999963  0.008615  0.000308  0.000000      0.0      0.0      0.0      0.0   \n",
            "2  0.999962  0.008750  0.000000  0.000000      0.0      0.0      0.0      0.0   \n",
            "3  0.999959  0.009000  0.000000  0.000000      0.0      0.0      0.0      0.0   \n",
            "4  0.999918  0.012832  0.000000  0.000167      0.0      0.0      0.0      0.0   \n",
            "\n",
            "   V1_14.0  V1_15.0  ...  V2_5.0  V2_50.0  V2_6.0  V2_7.0  V2_8.0  V2_9.0  \\\n",
            "0      0.0      0.0  ...     0.0  0.00008     0.0     0.0     0.0     0.0   \n",
            "1      0.0      0.0  ...     0.0  0.00000     0.0     0.0     0.0     0.0   \n",
            "2      0.0      0.0  ...     0.0  0.00000     0.0     0.0     0.0     0.0   \n",
            "3      0.0      0.0  ...     0.0  0.00000     0.0     0.0     0.0     0.0   \n",
            "4      0.0      0.0  ...     0.0  0.00000     0.0     0.0     0.0     0.0   \n",
            "\n",
            "      V2_?  V5_NEGATIVE  Target_NO  Target_YES  \n",
            "0  0.00000     0.000080   0.000000    0.000080  \n",
            "1  0.00000     0.000308   0.000000    0.000308  \n",
            "2  0.00025     0.000250   0.000000    0.000250  \n",
            "3  0.00000     0.000200   0.000000    0.000200  \n",
            "4  0.00000     0.000167   0.000167    0.000000  \n",
            "\n",
            "[5 rows x 70 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7.Handling Imbalance data\n",
        "from sklearn.utils import resample\n",
        "\n",
        "minority_class = one_hot_encoded_data[one_hot_encoded_data['V3'] == 'minority_class']\n",
        "majority_class = one_hot_encoded_data[one_hot_encoded_data['V3'] == 'majority_class']\n",
        "\n",
        "# Downsample the majority class\n",
        "majority_downsampled = resample(majority_class, replace=False, n_samples=len(minority_class), random_state=42)\n",
        "\n",
        "# Combine the downsampled majority class with the minority class\n",
        "balanced_data = pd.concat([minority_class, majority_downsampled])"
      ],
      "metadata": {
        "id": "65vMj466OQ5w"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RmuoNhVOWUL",
        "outputId": "85d98365-23aa-4d06-94c5-a467cd98e5c0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 533 entries, 0 to 747\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   V1      533 non-null    object \n",
            " 1   V2      533 non-null    object \n",
            " 2   V3      533 non-null    float64\n",
            " 3   V4      533 non-null    float64\n",
            " 4   V5      533 non-null    object \n",
            " 5   Target  533 non-null    object \n",
            "dtypes: float64(2), object(4)\n",
            "memory usage: 29.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8.Splitting the data into test and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = ['V1','V2','V3','V4','V5']\n",
        "X = df.loc[:, features]\n",
        "y = df.loc[:, ['Target']]\n",
        "\n",
        "# split into 70:30 ration\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "# describes info about train and test set\n",
        "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
        "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
        "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
        "print(\"Number transactions y_test dataset: \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKZX6kfeOasb",
        "outputId": "a3ad7deb-4197-4a39-85af-4ed8212f2ffe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number transactions X_train dataset:  (373, 5)\n",
            "Number transactions y_train dataset:  (373, 1)\n",
            "Number transactions X_test dataset:  (160, 5)\n",
            "Number transactions y_test dataset:  (160, 1)\n"
          ]
        }
      ]
    }
  ]
}